{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPLKO Moduł 12 - praca domowa - Wdrażanie modelu\n",
    "\n",
    "To dwunasta praca domowa w Programie szkoleniowym Klasyfikacja obrazu od Deep Drive PL\n",
    "\n",
    "Twoim zadaniem w tym module będzie:\n",
    "- [ ] Wdrożenie jednego ze swoich modeli jako aplikację demo: modelu do klasyfikacji rysunków z QuickDraw, modelu wytrenowanego z wykorzystaniem transfer learningu, modelu do klasyfikacji binarnej\n",
    "- [ ] Wykorzystaj np. FastAPI, Streamlit lub Gradio App\n",
    "- [ ] Udostępnij screenshot wdrożonej aplikacji na Discordzie `#klasyfikacja-wyniki`\n",
    "\n",
    "Extra - dodatkowo możesz:\n",
    "- Skorzystać z technik takich jak Torch Serve, TensorFlow Serving czy Nvidia Triton Inference server\n",
    "\n",
    "Jako rozwiązanie prześlij kod źródłowy z którego korzystasz - notebook/skrypt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir('/media/jakub/D/BarkDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(img_size,num_classes):\n",
    "    inputs = tf.keras.layers.Input(shape=(img_size, img_size, 3))\n",
    "    \n",
    "    base_model = tf.keras.applications.ResNet50(include_top=False, \n",
    "                                                        input_tensor=inputs, weights=\"imagenet\")\n",
    "\n",
    "    # New top\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(base_model.output)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2, name=\"top_dropout\")(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"ResNet50\")\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=1e-5, weight_decay=1e-4)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"],\n",
    "        run_eagerly=True\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_model(224, len(classes))\n",
    "model.load_weights('/home/jakub/BarkClassifier/weights.06-0.33_resnet50_2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "    image = image.resize((224, 224))\n",
    "    batch = np.expand_dims(image, 0)\n",
    "    batch = tf.keras.applications.resnet.preprocess_input(batch) / 255.0\n",
    "    pred = model.predict(batch)[0]\n",
    "    return {classes[i]: float(pred[i]) for i in range(len(classes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7862/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4a18184910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imagein = gr.inputs.Image()\n",
    "label = gr.outputs.Label(num_top_classes=5)\n",
    "cls = gr.outputs.Textbox(type=\"auto\", label=None)\n",
    "\n",
    "images = [[\"BOJ_1.jpg\"],\n",
    "          [\"BOP_1.jpg\"],\n",
    "          [\"CHR_1.jpg\"],\n",
    "          ['EPB_1.jpg'],\n",
    "          ['EPN_1.jpg']]\n",
    "\n",
    "gr.Interface([predict], \n",
    "            imagein, \n",
    "            label,\n",
    "            title=\"ResNet50 Tree Bark Classification\",\n",
    "            description=\"Bark Classification based on https://github.com/ulaval-damas/tree-bark-classification\",\n",
    "            examples=images).launch();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wyślij rozwiązanie\n",
    "Możesz skorzystać z jednego z poniższych sposobów:\n",
    "**mailem na specjalny adres** ze strony pracy domowej w panelu programu prześlij jedno z poniższych:\n",
    "- notebooka (jeżeli plik ma mniej niż np. 10MB)\n",
    "- notebooka w zipie\n",
    "- link do Colaba (udostępniony)\n",
    "- link do pliku przez GDrive/Dropboxa/WeTransfer/...\n",
    "- pdfa (poprzez download as pdf)\n",
    "- jako plik w repozytorium na np. GitHubie, by budować swoje portfolio (wtedy uważaj na wielkość pliku, najlepiej kilka MB, Max 25MB)\n",
    "\n",
    "Najlepiej, by w notebooku było widać wyniki uruchomienia komórek, chyba, że przez nie plik będzie mieć 100+MB wtedy najlepiej Colab lub jakieś przemyślenie co poszło nie tak (zbyt dużo dużych zdjęć wyświetlonych w komórkach).\n",
    "\n",
    "## Co otrzymasz?\n",
    "Informację zwrotną z ewentualnymi sugestiami, komentarzami."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
